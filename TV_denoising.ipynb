{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e3c757",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "import scipy.ndimage\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import metrics\n",
    "import pandas as pd\n",
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba252627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST dataset\n",
    "\n",
    "np.random.seed(100)\n",
    "\n",
    "# Import MNIST\n",
    "(a_tr, labels_train), (a_test, labels_test) = mnist.load_data()\n",
    "\n",
    "# Smaller sets\n",
    "N_test_set = 100\n",
    "N_train_set = 7000\n",
    "N_val = 3000\n",
    "N = a_tr.shape[1]\n",
    "\n",
    "# this is a matrix of matrices\n",
    "a_test = a_test[0:N_test_set, :, :] / 255.\n",
    "a_train = a_tr[0:7000, :, :] / 255.\n",
    "a_val = a_tr[7000:10000, :, :] / 255.\n",
    "\n",
    "# Add noise\n",
    "noise_lev = 0.1\n",
    "\n",
    "# These are matrices of vectors\n",
    "b_test = a_test + noise_lev * np.random.randn(N_test_set, N, N)\n",
    "b_train = a_train + noise_lev * np.random.randn(7000, N, N)\n",
    "b_val = a_val + noise_lev * np.random.randn(N_val, N, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f281968",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Algorithm functions\n",
    "\n",
    "def prox_g_d(x, Lambda):\n",
    "    return np.clip(x, -Lambda, Lambda)\n",
    "\n",
    "# Create the operator D (and D^T)\n",
    "def image_grad(x):\n",
    "    x_img = x.reshape(N,N)\n",
    "    x_diff_v = np.diff(x_img,axis=0)\n",
    "    x_diff_h = np.diff(x_img,axis=1)\n",
    "    return [np.concatenate((x_diff_v.reshape((N-1)*N),x_diff_h.reshape((N-1)*N)))]\n",
    "\n",
    "def image_div(x):\n",
    "    x_v = x[0:(N-1)*N].reshape(N-1,N)\n",
    "    x_h = x[(N-1)*N:].reshape(N,N-1)\n",
    "    x_div_v = np.concatenate((np.zeros((1,N)),x_v),axis=0) - np.concatenate((x_v,np.zeros((1,N))),axis=0)\n",
    "    x_div_h = np.concatenate((np.zeros((N,1)),x_h),axis=1) - np.concatenate((x_h,np.zeros((N,1))),axis=1)\n",
    "    return [(x_div_v + x_div_h).reshape(N**2)]\n",
    "\n",
    "D_Op = scipy.sparse.linalg.LinearOperator((2 * N * (N - 1), N ** 2), \n",
    "                                          matvec=image_grad, rmatvec=image_div)\n",
    "\n",
    "# We compute here D_TV(x, f_\\lambda(y)). Inputs vectors, outputs number\n",
    "def breg_dist_tv(x, y):\n",
    "    gradx = D_Op.matvec(x)\n",
    "    grady = D_Op.matvec(y)\n",
    "    normx = np.linalg.norm(gradx, ord=1)\n",
    "    return normx - np.dot(np.sign(grady), gradx)\n",
    "\n",
    "\n",
    "# We want to do here FISTA on the dual of ||x-y||^2+laTV(x) -> min_x\n",
    "\n",
    "# First the inertial function\n",
    "\n",
    "iner = 12\n",
    "\n",
    "def beta(tk, k):\n",
    "    t_next = (k + iner - 1) / iner\n",
    "    return (tk - 1) / t_next, t_next\n",
    "\n",
    "# Now the algorithm\n",
    "\n",
    "def dual_fista(lam, y):\n",
    "    y = y.reshape(N ** 2)\n",
    "    gamma = 1 / 8\n",
    "    u = np.zeros((2 * N * (N - 1)))\n",
    "    x = np.zeros((N ** 2))\n",
    "    tk = 1\n",
    "    z = u.copy()\n",
    "    nor1 = 1\n",
    "    t = 0\n",
    "    while nor1 >= 1e-8:\n",
    "        beta_n, tk = beta(tk, t)\n",
    "        u_prev = u.copy()\n",
    "        gz = D_Op.matvec(y - D_Op.rmatvec(z))\n",
    "        u = prox_g_d(z + gamma * gz, lam)\n",
    "        z = u + beta_n * (u - u_prev)\n",
    "        x_old = x.copy()\n",
    "        x = y - D_Op.rmatvec(u)\n",
    "        nor1 = np.linalg.norm(x - x_old, ord=1)\n",
    "        t += 1\n",
    "    return x.reshape((N, N))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421ad398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lambda_Lambda functions\n",
    "\n",
    "def train_TV(lamb):\n",
    "    def compute_distance(i):\n",
    "        f_TV = dual_fista(lamb, b_train[i, :, :]).reshape(N ** 2)\n",
    "        return breg_dist_tv(a_train[i, :, :].reshape(N ** 2), f_TV)\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        distances = np.array(list(executor.map(compute_distance, range(N_train_set))))\n",
    "\n",
    "    return np.mean(distances)\n",
    "\n",
    "\n",
    "def get_lambda_star(lamb):  # here lambda is a vector\n",
    "    TV_err = np.array([train_TV(l) for l in lamb])\n",
    "    return lamb[np.argmin(TV_err)], TV_err.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bb7d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lamb = np.logspace(-4, -1, num=50)\n",
    "\n",
    "lambda_star, L_lambda_star = get_lambda_star(lamb)\n",
    "\n",
    "print(r'$\\lambda^*$: ', lambda_star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378a8e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ER functions\n",
    "\n",
    "def val_TVn(n, lamb):\n",
    "    sel = np.random.permutation(N_val)[:n]\n",
    "    a_tr = a_val[sel, :, :]\n",
    "    b_tr = b_val[sel, :, :]\n",
    "\n",
    "    def compute_distance(i):\n",
    "        f_TV = dual_fista(lamb, b_tr[i, :, :]).reshape(N ** 2)\n",
    "        return breg_dist_tv(a_tr[i, :, :].reshape(N ** 2), f_TV)\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        distances = np.array(list(executor.map(compute_distance, range(n))))\n",
    "\n",
    "    return np.mean(distances)\n",
    "\n",
    "\n",
    "def cvlambda(n, lamb):  # here lambda is a vector\n",
    "    TV_err = np.array([val_TVn(n, l) for l in lamb])\n",
    "    return TV_err.min(), lamb[np.argmin(TV_err)]\n",
    "\n",
    "def get_L_hat(L_lambda_star, lamb, N_vec, n_it):\n",
    "    Deltan = np.zeros((len(N_vec), n_it))\n",
    "    for i in range(len(N_vec)):\n",
    "        for j in range(n_it):\n",
    "            Deltan[i, j] = np.abs(L_lambda_star - cvlambda(N_vec[i], lamb)[0])\n",
    "    return Deltan                             \n",
    "                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc7f502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ER plot\n",
    "N_vec = np.arange(10, 160, 10)\n",
    "n_it = 30  # The perfect number of iterations is 30\n",
    "\n",
    "deltaTV = get_L_hat(L_lambda_star, lamb, N_vec, n_it)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db89eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "DeltaTV = np.zeros(np.shape(deltaTV))\n",
    "for i in range(len(deltaTV)):\n",
    "    DeltaTV[i] = deltaTV[i] * np.sqrt(N_vec[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01224298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure\n",
    "dfTV = pd.DataFrame(DeltaTV)\n",
    "meanDelTV = dfTV.mean(axis='columns')\n",
    "lowerTV = np.quantile(DeltaTV, 0.05, axis=1)\n",
    "upperTV = np.quantile(DeltaTV, 0.95, axis=1)\n",
    "\n",
    "plt.close('all')\n",
    "fig, ax1 = plt.subplots(figsize=(20, 5), dpi=100)\n",
    "# fig.suptitle(\"Excess risk behaviour\", fontsize=20)\n",
    "ax1.plot(N_vec, meanDelTV, '-')\n",
    "ax1.scatter(N_vec, meanDelTV, color='red', s=50)\n",
    "ax1.fill_between(N_vec, lowerTV, upperTV, alpha=0.2)\n",
    "ax1.set_ylabel(r'$\\Delta(n)\\sqrt{n}$', fontsize=25)\n",
    "ax1.set_xlabel(r'$n$', fontsize=25)\n",
    "# ax1.legend(fontsize=20)\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "plt.savefig(\"./ER_TVdenoising.pdf\", bbox_inches='tight')\n",
    "plt.show(block=False)  # This should go before show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155b9d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We compute different reg parameters here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b98a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "L_lambda_hat1, lambda_hat1 = cvlambda(100, lamb)\n",
    "\n",
    "print(r'$\\widehat{\\lambda}$:', lambda_hat1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981a7ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "L_lambda_hat2, lambda_hat2 = cvlambda(100, lamb)\n",
    "\n",
    "print(r'$\\widehat{\\lambda}$:', lambda_hat2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e097459",
   "metadata": {},
   "outputs": [],
   "source": [
    "L_lambda_hat3, lambda_hat3 = cvlambda(100, lamb)\n",
    "\n",
    "print(r'$\\widehat{{\\lambda}}$:', lambda_hat3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ead776a",
   "metadata": {},
   "outputs": [],
   "source": [
    "L_lambda_hat4, lambda_hat4 = cvlambda(100, lamb)\n",
    "\n",
    "print(r'$\\widehat{{\\lambda}}$:', lambda_hat4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d45b5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot for two test example\n",
    "\n",
    "a1 = a_test[42, :, :]\n",
    "b1 = b_test[42, :, :]\n",
    "a1_tv= dual_fista(lambda_hat1, b1)\n",
    "a2_tv= dual_fista(lambda_hat2, b1)\n",
    "\n",
    "a2 = a_test[55, :, :]\n",
    "b2 = b_test[55, :, :]\n",
    "a3_tv= dual_fista(lambda_hat3, b2)\n",
    "a4_tv= dual_fista(lambda_hat4, b2)\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(2, 4, figsize=(20, 8))\n",
    "\n",
    "axs[0, 0].imshow(a1, cmap='gray', vmin=0, vmax=1)\n",
    "axs[0, 0].set_title('Original', fontsize=20)\n",
    "axs[0, 1].imshow(b1, cmap='gray', vmin=0, vmax=1)\n",
    "axs[0, 1].set_title(r'Noisy, $D_{{\\mathrm{{TV}}}}$: {:.4f}'\n",
    "                    .format(breg_dist_tv(a1.reshape(N**2), b1.reshape(N**2))), fontsize=20)\n",
    "axs[0, 2].imshow(a1_tv, cmap='gray', vmin=0, vmax=1)\n",
    "axs[0, 2].set_title(r'$\\widehat{{\\lambda}}_1=0.0494$, $D_{{\\mathrm{{TV}}}}$: {:.4f}'\n",
    "                    .format(breg_dist_tv(a1.reshape(N**2), a1_tv.reshape(N**2))), fontsize=20)\n",
    "axs[0, 3].imshow(a2_tv, cmap='gray', vmin=0, vmax=1)\n",
    "axs[0, 3].set_title(r'$\\widehat{{\\lambda}}_2=0.0091$, $D_{{\\mathrm{{TV}}}}$: {:.4f}'\n",
    "                    .format(breg_dist_tv(a1.reshape(N**2), a2_tv.reshape(N**2))), fontsize=20)\n",
    "\n",
    "axs[1, 0].imshow(a2, cmap='gray', vmin=0, vmax=1)\n",
    "axs[1, 0].set_title('Original', fontsize=20)\n",
    "axs[1, 1].imshow(b2, cmap='gray', vmin=0, vmax=1)\n",
    "axs[1, 1].set_title(r'Noisy, $D_{{\\mathrm{{TV}}}}$: {:.4f}'\n",
    "                    .format(breg_dist_tv(a2.reshape(N**2), b2.reshape(N**2))), fontsize=20)\n",
    "axs[1, 2].imshow(a3_tv, cmap='gray', vmin=0, vmax=1)\n",
    "axs[1, 2].set_title(r'$\\widehat{{\\lambda}}_3=0.0025$, $D_{{\\mathrm{{TV}}}}$: {:.4f}'\n",
    "                    .format(breg_dist_tv(a2.reshape(N**2), a3_tv.reshape(N**2))), fontsize=20)\n",
    "axs[1, 3].imshow(a4_tv, cmap='gray', vmin=0, vmax=1)\n",
    "axs[1, 3].set_title(r'$\\widehat{{\\lambda}}_4=0.0002$, $D_{{\\mathrm{{TV}}}}$: {:.4f}'\n",
    "                    .format(breg_dist_tv(a2.reshape(N**2), a4_tv.reshape(N**2))), fontsize=20)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"./tvrecov_test_combined.pdf\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
